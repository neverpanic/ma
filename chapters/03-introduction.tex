% vim:noet:sts=2:ts=2:sw=2:smarttab:tw=120

\chapter{Introduction}
	\label{chapter:intro}
	Embedded devices are on the rise. While internet-connected refrigerators, which have been journalists' favorite
	prediction for the future, are still a long way off, other turing complete devices have found their way into daily
	life. Taking a look around an ordinary kitchen reveals devices like a fully automatic coffee machine, a digital
	kitchen scale, a dish washer, or even a WiFi-enabled bar code scanner helping users update their shopping list. All of
	those contain microcontrollers, each serving a special purpose. And it seems these are just the first vistas of an
	emerging trend: At the embedded world conference 2014 in Nuremberg, the \emph{Internet of Things}, i.e.\ the
	interconnection of these embedded devices, was a very popular topic. The world might be on the verge of being flooded
	with highly integrated and networked microcontroller-driven devices.

	% See
	% http://www.is2t.com/java-in-embedded-systems/
	% http://www.eetimes.com/document.asp?doc_id=1318980
	% http://www.eetimes.com/document.asp?doc_id=1317511
	% http://www.eetimes.com/document.asp?doc_id=1262568
	% http://www.eetimes.com/document.asp?doc_id=1261676
	% http://www.eetimes.com/document.asp?doc_id=1319569

	These single-purpose embedded devices are commonly programmed in C and the like. However, with increasing software
	complexity of these devices, Java has been emerging as an appropriate alternative for a number of reasons. Java's ease
	of use, large standard library and suitability for complex projects are increasingly called for even in embedded
	software. Its type safe design prevents memory faults that could be caused by out of bounds array accesses or mistakes
	in manual memory management, eliminating a whole class of potential bugs.

	These advantages used to come at the price of reduced performance and increased memory usage due to the need for
	runtime environment and garbage collection, but are challenged by new virtual machines and compilers.
	\emph{Ahead-of-time} compilation, i.e.\ translation to native code before execution, has been gaining popularity
	lately: Google revealed switching its Android platform to a new runtime environment, which is expected to
	\enquote{speed up apps by around 100~\%}~\cite{anthony:13:android-art} using ahead-of-time
	compilation~\cite{lindner:14:android-art}. Microsoft declared a similar intention for its .NET
	platform~\cite{lardinois:14:dotnet-aot}. Oracle and others have developed Java virtual machines targeted at embedded
	systems~\cite{merritt:13:java-for-IoT, maxfield:12:IS2T-JVM}.

	\section{The KESO Multi-JVM}
		\label{sec:intro:keso}
		The KESO Java virtual machine uses ahead-of-time compilation and assumes all application code is available for
		analysis at compile time. This \enquote{closed world} assumption makes aggressive optimizations possible. Built on
		top of an OSEK/VDX~\cite{OSEKSpec223} or AUTOSAR~\cite{autosar:06:sws_os} \gls{rtos}, KESO allows writing
		applications and even device drivers in Java and targets deeply embedded systems with real-time
		requirements~\cite{thomm:10:jtres}. KESO's compiler \emph{JINO} analyzes the application code, tailors the runtime
		environment (including the Java standard library) to the application's needs and emits standards-compliant C to be
		compiled for the target architecture.

		\Cref{fig:intro:overview} gives an architectural overview of a KESO system. The runtime environment provides an
		abstraction layer on top of the OSEK/VDX or AUTOSAR \gls{rtos} and allows configurable access to specific memory
		addresses for memory-mapped I/O, e.g.\ in device drivers. KESO also provides a mechanism similar to the \gls{jni} to
		execute native code. A KESO system can contain multiple protection realms (so-called \emph{domains}), each of which
		can have a number of tasks, resources, alarms, and \glspl{isr}, its own heap region, and garbage collection
		mechanism. Domains communicate using a \gls{rpc} mechanism called \emph{portals}. The KESO runtime environment
		ensures objects passed through portals cannot interfere with other protection domains.

		\begin{figure}
			\begin{center}
				\input{images/keso-schematic.tex}
			\end{center}
			\caption[Schematic overview of a KESO system]{%
				Schematic overview of a KESO system. An OSEK (or AUTOSAR, not depicted) \gls{rtos} runs on a microcontroller. On
				top of the operating system, the KESO runtime environment provides services and abstractions used by the
				application, such as \gls{rpc} primitives or device drivers. Multiple protection realms (\emph{domains}) can
				contain multiple tasks each, have their own resources, heap, and garbage collection method and communicate
				safely using \emph{portals}.}
			\label{fig:intro:overview}
		\end{figure}

		Because Java is a type safe language, KESO can employ a combination of compile-time and runtime checks to ensure
		that applications cannot modify memory outside their protection realm even in the absence of specialized hardware
		for this task, such as a \gls{mpu} or \gls{mmu}. Since KESO guarantees complete isolation even when one of the tasks
		misbehaves, multiple applications can be run on the same system without interfering with each other, possibly
		further reducing required chip size, energy consumption and production costs. Due to the reduction of structure
		sizes in modern computing chips, dealing with transient soft errors such as bit flips is mandatory for critical
		applications. Software-based mechanisms for isolation are at a disadvantage compared to \glspl{mcu} with
		hardware-based memory protection such as \glspl{mpu} and \glspl{mmu}, which offer protection against errors caused
		by this problem class. Previous work on KESO attempts to compensate this~\cite{thomm:11:jtres, stilkerich:13:lctes}.

	\section{Motivation}
		\label{sec:intro:motivation}

		Manual memory management using library functions has been the de-facto standard method of dealing with dynamic
		memory needs in C and \C++{}. It provides fine-granular control over applications' memory allocation behavior, but
		comes with a number of downsides. Programming mistakes can lead to leaks and dangling pointers, which in turn can
		lead to security vulnerabilities or crashes. As a consequence, developers need to be very careful while writing code
		that uses manual memory management, in particular when used in safety-critical components.

		In order to address these drawbacks, a number of automatic memory management techniques such as garbage collection
		can be used. Instead of having the software developer deal with unused memory manually, garbage collection
		automatically identifies slices of memory that are no longer referenced from the working data set and reclaims them,
		avoiding memory leaks and dangling pointers entirely. However, unused memory is not reclaimed until the next garbage
		collector run, potentially reducing the predictability of an application's memory allocation behavior. Compared to
		manual memory management, garbage collection is less error-prone at the cost of not reclaiming memory immediately
		and being less predictable. Both approaches need to deal with fragmentation caused by reclaiming in a sequence that
		differs from the allocation order.

		A third alternative that exists in both manual and automatic variants is a region-based approach to managing memory.
		Each allocated piece of memory is assigned to one of many memory regions (also called \emph{pools}). Unused regions
		are reclaimed as a whole, avoiding external fragmentation completely. A pool can only be safely recycled if all
		memory allocated from it is no longer needed, possibly extending the lifetime of a pool and preventing re-use of
		otherwise unused memory if the mapping from allocation to memory region is a bad match. Since region-based memory
		management does not suffer from external fragmentation because it does not recycle its pools partially, the time
		needed for allocations is easily predictable and allocation can be implemented in $\mathcal O(1)$. This is an
		advantage over both manual memory management and garbage collection, which do not always guarantee tight upper
		bounds for memory management operations\footnote{This is not to say that they cannot, and there are a few algorithms
		that achieve good upper bounds for these operations by avoiding fragmentation or embracing it. See~\cite{strotz:14}
		for previous work in KESO about this problem and~\cite{pizlo:10:pldi} for the work it is based on.}.

		Manual region-based methods require developers to map allocation operations to the regions to be used to satisfy the
		requests. The Real-Time Specification for Java supports manual region-based approaches to memory management with the
		subclasses of its \texttt{javax.realtime.ScopedMemory} class~\cite{rtsj:06:scoped}. Manual methods feature
		predictable \glspl{wcet} and allow fine-granular control over the application's behavior related to memory, but
		suffer from the same potential problems present in (non-region-based) manual memory management.

		\todonote{Explain region inference, state that stack memory is a special case of region-based memory and outline how
		EA can be used to infer region information for local objects. Detail how I think scope extension is beneficial for
		a lot of patterns present in Java and how it will be a simple approach towards full region inference.}

	\section{Previous Work}
		\label{sec:intro:prev}
		\todonote{Recall what my bachelor thesis was about, find a few similar examples of people that use type-safe
		languages and ahead-of-time compilation to achieve isolation. Outline why escape analysis (or alias analysis in
		general) can not be as precise as it is in type-safe languages in the presence of pointers.}

	\section{Document Structure}
		\label{sec:intro:document-structure}
		\todonote{Explain what the chapters contain.}
